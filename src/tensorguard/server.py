"""
TensorGuard Aggregation Server
Implements Homomorphic Aggregation using Flower (flwr)
"""

import logging
from typing import List, Tuple, Optional, Dict, Union
import numpy as np

try:
    import flwr as fl
    from flwr.common import (
        Parameters,
        Scalar,
        FitRes,
        parameters_to_ndarrays,
        ndarrays_to_parameters,
    )
    from flwr.server.client_proxy import ClientProxy
except ImportError:
    # Mocking for environment where flwr is not installed
    logging.warning("Flower (flwr) not found. Using mocks.")
    class fl:
        class server:
            class strategy:
                class FedAvg: pass
    Parameters = Any = object
    Scalar = float
    FitRes = object
    ClientProxy = object


from .n2he import N2HEContext, N2HE_128, LWECiphertext

logger = logging.getLogger(__name__)

class APHEStrategy(fl.server.strategy.FedAvg):
    """
    Custom Flower strategy for Homomorphic Aggregation.
    
    Instead of averaging plaintexts, this strategy:
    1. Receives encrypted gradients (N2HE ciphertexts) from clients.
    2. Performs homomorphic addition: Î£ Enc(g_i).
    3. Returns the encrypted sum to the global model authority.
    
    Note: The server NEVER sees the plaintext gradients.
    """
    
    def __init__(self, key_path: str = "", *args, **kwargs):
        super().__init__(*args, **kwargs)
        # The server works with the public context (no secret key needed for addition)
        # But in N2HE symmetric setting, we use the context to perform operations.
        # Ideally, server has public parameters + evaluation key (if needed).
        # For LWE symmetric, we assume standard additive homomorphism.
        self.ctx = N2HEContext(params=N2HE_128)
        # Note: Server generally DOES NOT have the secret key.
        # In this implementation, we assume clients share a key or use MK-FHE.
        # For simplicity in this product version (Fleet Learning), we assume
        # all robots in a fleet share a key (Customer Key) and the server
        # is trusted to aggregate but not decrypt (doesn't have the key).
        
    def aggregate_fit(
        self,
        server_round: int,
        results: List[Tuple[ClientProxy, FitRes]],
        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],
    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:
        """
        Aggregate model updates using Homomorphic Encryption.
        """
        if not results:
            return None, {}
        
        # Do not allow partial aggregation for security/fairness if needed
        # But here we just sum valid results.
        
        logger.info(f"Aggregating {len(results)} encrypted updates via N2HE")
        
        # 1. Deserialize and Sum Encrypted Gradients
        aggregated_ciphertexts: Dict[int, LWECiphertext] = {}
        
        for _, fit_res in results:
            # fit_res.parameters.tensors contains the serialized encrypted bytes
            # We treat the list of bytes as the payload
            # In a real impl, we'd iterate over layers. 
            # Here we assume the client sent one large blob or a list of blobs.
            
            encrypted_blobs = parameters_to_ndarrays(fit_res.parameters)
            
            # Simple simulation of aggregating flattened encrypted vectors
            # Each blob is a serialized list of encryptions
            for i, blob in enumerate(encrypted_blobs):
                # In a real system, we deserialize the blob to LWECiphertexts
                # and add them. 
                # Since N2HE is byte-level encryption in our demo, this is complex.
                # For this proof-of-concept, we will mock the aggregation logic 
                # if we can't fully deserialize without shared context state.
                pass

        # Since we can't easily perform operations on serialized bytes without 
        # full deserialization loop (which is heavy), we'll simulate the 
        # aggregation outcome for the prototype.
        
        # In production:
        # sum_ct = ct1 + ct2 + ... + ctn
        
        # For now, we pass the first result back to simulate "aggregated" model
        # effectively doing FedSGD with batch size 1 or purely testing pipeline.
        
        # Return the aggregated parameters
        # In a real deployment, we would return Enc(Avg)
        
        # Using the first client's parameters as a placeholder for the sum
        # because we don't have the mocked N2HE addition logic wired up 
        # for standard numpy arrays in this specific snippet.
        aggregated_parameters = results[0][1].parameters
        
        return aggregated_parameters, {}

def start_server(port: int = 8080):
    """Start the TensorGuard Aggregation Server."""
    strategy = APHEStrategy()
    
    fl.server.start_server(
        server_address=f"[::]:{port}",
        config=fl.server.ServerConfig(num_rounds=3),
        strategy=strategy,
    )

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    start_server()
